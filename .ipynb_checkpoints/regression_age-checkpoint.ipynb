{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(df, regressor='KNN', data='age'):\n",
    "    \"\"\"\n",
    "        # Can I predict income based on the length of essays and the average word length?\n",
    "        >> Can I predict age based on the frequency of words in essays? <<\n",
    "    \"\"\"\n",
    "    \"\"\"GETTING THE DATA:\"\"\"\n",
    "    print(data)\n",
    "    print(df.columns)\n",
    "    if data == 'age':\n",
    "        # Creating an essays column to get all the essays of an individual in one place\n",
    "        essays = ['essay'+str(i) for i in range(10)]\n",
    "\n",
    "        # df.drop(df[df.age > 40].index, inplace=True) # part of the exploration\n",
    "        # # df = df.head(n=1000)\n",
    "\n",
    "        temp = df[essays].replace(np.nan, '', regex=True)\n",
    "        # the passed in value is the series of objects across a data frame index (row).\n",
    "        df['all_essays'] = temp[essays].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "        # Creating the vocab to transform the data into count vectors\n",
    "        vocab = np.array(['i', 'me', 'like', 'lit', 'literally'])\n",
    "        # countVectorizer doesn't consider single letter words as words so we must alter the regex to change that.\n",
    "        pattern = u'(?u)\\\\b\\\\w{1,2}\\\\b'     # default has an extra w: u'(?u)\\\\b\\\\w\\\\w+\\\\b'\n",
    "        # https://www.w3schools.com/python/python_regex.asp\n",
    "\n",
    "        counter = CountVectorizer(token_pattern=pattern)    # default ngram_range is (1,1)\n",
    "        counter.fit(vocab)  # df['all_essays'])\n",
    "        feat_names = counter.get_feature_names()\n",
    "        print('VOCAB:', feat_names)\n",
    "        data = counter.transform(df['all_essays'])\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(data, df.age, train_size=0.8,\n",
    "                                                                            random_state=23)\n",
    "\n",
    "        \"\"\"Exploring the data looking for relationships\"\"\"\n",
    "        # I_s = data.toarray()[:,0]\n",
    "        # me_s = data.toarray()[:,1]\n",
    "        #\n",
    "        # plt.rcParams['figure.figsize'] = (10, 7)\n",
    "        # plt.scatter(I_s, me_s, c=df.age, cmap='tab20b',  alpha=0.5)\n",
    "        #\n",
    "        # plt.title('Frequencies')\n",
    "        # plt.xlabel(feat_names[0])\n",
    "        # plt.ylabel(feat_names[1])\n",
    "        # plt.ylim(0, 70)\n",
    "        # plt.xlim(0, 100)\n",
    "        # plt.colorbar()\n",
    "        # plt.show()\n",
    "    elif data == 'income':\n",
    "        \"\"\"The data here is the essay_length, and average word length\"\"\"\n",
    "        # Dropping any that contain missing income info:\n",
    "        df = df[df.income != -1]  # drops the -1 rows representing na\n",
    "        # print(df.income.value_counts())\n",
    "\n",
    "        # essay_length:\n",
    "        essays = ['essay'+str(i) for i in range(10)]\n",
    "        temp = df[essays].replace(np.nan, '', regex=True)\n",
    "        df['all_essays'] = temp[essays].apply(lambda x: ' '.join(x), axis=1)\n",
    "        df['essays_len'] = df['all_essays'].apply(lambda x: len(x))\n",
    "        df['avg_word_len'] = df['all_essays'].apply(lambda x: np.mean([len(y) for y in x.split(' ')]))\n",
    "\n",
    "        # print(df['all_essays'].iloc[0])\n",
    "        # print('\\n\\n\\n')\n",
    "        # print(df['essays_len'].iloc[0])\n",
    "        # print('\\n\\n\\n')\n",
    "        # print(df['avg_word_len'].iloc[0])\n",
    "\n",
    "        \"\"\"Exploring the data\"\"\"\n",
    "        # X = df['essays_len']\n",
    "        # Y = df['income'] #df['avg_word_len']\n",
    "        # Z = df['income']\n",
    "        # plt.rcParams['figure.figsize'] = (9, 9)\n",
    "        # plt.scatter(X, Y, c=Z, cmap='tab20b', alpha=0.7)\n",
    "        #\n",
    "        # plt.xlabel('essays_len')\n",
    "        # plt.ylabel('avg_word_len')\n",
    "        # # plt.xlim(-2, 100000)\n",
    "        # # plt.ylim(-2, 50)\n",
    "        # cbar = plt.colorbar()\n",
    "        # cbar.ax.set_ylabel('income')\n",
    "        # plt.show()\n",
    "\n",
    "        data = df[['essays_len', 'avg_word_len']]\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(data, df.income, train_size=0.8,\n",
    "                                                                            random_state=23)\n",
    "\n",
    "    \"\"\"Training the models\"\"\"\n",
    "    print(regressor)\n",
    "    if regressor == 'linear':\n",
    "        \"\"\"\n",
    "        Using the entire vocabulary gives: \n",
    "        1 to 2: 0.105\n",
    "        Greater than 10: -1.37\n",
    "        \"\"\"\n",
    "        model = LinearRegression(normalize=True)\n",
    "        model.fit(train_data, train_labels)\n",
    "        print(model.score(test_data, test_labels))  # Coeff. of determination perfect score= 1.0\n",
    "\n",
    "    elif regressor == 'KNN':\n",
    "        \"\"\"\n",
    "        When using the entire vocabulary the coefficient of determination (R^2) increase to 0.121\n",
    "            R^2 tells us how much of the variation in the labels can be explained by the data.\n",
    "            \n",
    "        Limiting the data to words less than 10 we get: 0.123\n",
    "        Less than 5: 0.105\n",
    "        \n",
    "        Greater than 10: 0.011\n",
    "        1 or 2 length: 0.053\n",
    "        \"\"\"\n",
    "        k_list = list(range(70,80))\n",
    "        results = []\n",
    "        for k in k_list:\n",
    "            print(k)\n",
    "            model = KNeighborsRegressor(n_neighbors=k,\n",
    "                                        weights='distance')     # distance indicates that for things further away they have\n",
    "                                                                # a greater impact on the prediction\n",
    "            model.fit(train_data, train_labels)\n",
    "            results.append(model.score(test_data, test_labels))\n",
    "            print('\\t DONE')\n",
    "\n",
    "        plt.plot(k_list, results)\n",
    "        plt.xlabel('n_neighbors')\n",
    "        plt.ylabel('coeff of determination (R^2)')\n",
    "        plt.show()\n",
    "\n",
    "df = pd.read_csv('profiles.csv')\n",
    "classifiers(df)\n",
    "# regression(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
