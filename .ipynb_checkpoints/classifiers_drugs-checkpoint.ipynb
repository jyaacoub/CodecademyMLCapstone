{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing  # For normalizing the data\n",
    "\n",
    "# Classification imports required\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Regression imports required\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION: \n",
    "*Can we build an accurate enough classifier to determine whether or not a person does drugs depending on the following \n",
    "data: 'age', 'sex_i', 'drinks','smokes'?*\n",
    "\n",
    "## Classifiers used: \n",
    "* K-Nearest Neighbor\n",
    "* Support Vector Machine\n",
    "* Naive Bayes (features are countvectors of the essay portion of the data)\n",
    "\n",
    "### Getting the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the rows and creating meaningful columns\n",
    "To drop specific rows representing na for income: `df = df[df.income != -1]`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After\n",
      "age       False\n",
      "drugs     False\n",
      "sex       False\n",
      "drinks    False\n",
      "smokes    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('profiles.csv')\n",
    "df.dropna(subset=['age', 'drugs', 'sex', 'drinks', 'smokes'], inplace=True)\n",
    "print(\"\\nAfter\\n\" + str(df[['age', 'drugs', 'sex', 'drinks', 'smokes']].isna().any()))  # success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating meaningful columns/ mapping the data\n",
    "    For mapping specific groups we can use df.apply() as so:\n",
    "        df['does_drugs'] = df.apply(lambda row: 1 if (row.drugs == 'sometimes' or row.drugs == 'often') else 0, axis=1)\n",
    "        \n",
    "     Mapping this data I consider 'sometimes' and 'when drinking' to be the same in the case of smoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Meaningful columns\n",
    "df['sex_i'] = df.sex.map({'m': 0, 'f': 1})\n",
    "df['drinks_i'] = df.drinks.map({\"not at all\": 0, \"rarely\": 1, \"socially\": 2,\n",
    "                                \"often\": 3, \"very often\": 4, \"desperately\": 5})\n",
    "df['smokes_i'] = df.smokes.map({'no': 0, 'sometimes': 1, 'when drinking': 1,\n",
    "                                'trying to quit': 2, 'yes': 3})\n",
    "\n",
    "df['drugs_i'] = df.drugs.map({'never': 0, 'sometimes': 1, 'often': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:\n",
      "0    34830\n",
      "2     7280\n",
      "1      385\n",
      "Name: drugs_i, dtype: int64\n",
      "\n",
      "\n",
      "Features:\n",
      "count    42495.000000\n",
      "mean        32.714037\n",
      "std          9.866243\n",
      "min         18.000000\n",
      "25%         26.000000\n",
      "50%         30.000000\n",
      "75%         37.000000\n",
      "max         69.000000\n",
      "Name: age, dtype: float64\n",
      "2    30131\n",
      "1     5106\n",
      "3     3636\n",
      "0     3017\n",
      "4      384\n",
      "5      221\n",
      "Name: drinks_i, dtype: int64\n",
      "0    34624\n",
      "1     5016\n",
      "3     1756\n",
      "2     1099\n",
      "Name: smokes_i, dtype: int64\n",
      "0    25062\n",
      "1    17433\n",
      "Name: sex_i, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Printing out the counts\n",
    "print('Label:')\n",
    "print(df.drugs_i.value_counts())\n",
    "\n",
    "print('\\n\\nFeatures:')\n",
    "print(df.age.describe())\n",
    "print(df.drinks_i.value_counts())\n",
    "print(df.smokes_i.value_counts())\n",
    "print(df.sex_i.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data\n",
    "Normalizing data is only important when there are huge gaps in magnitude between feature data. So in this case where all our data is categorical it isn't really necessary.\n",
    "We must normalize the data here because the age column is magnitude greater than the categorical data\n",
    "\n",
    "The syntax for extracting rows from ndarrays is\n",
    "    `A_NEW = A[start_index_row : stop_index_row,start_index_columnn : stop_index_column)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  2  1  0]\n",
      " [35  3  0  0]] \n",
      "\n",
      "[[0.07843137 0.4        0.33333333 0.        ]\n",
      " [0.33333333 0.6        0.         0.        ]] \n",
      "\n",
      "        age  drinks_i  smokes_i  sex_i\n",
      "0  0.078431       0.4  0.333333    0.0\n",
      "1  0.333333       0.6  0.000000    0.0\n"
     ]
    }
   ],
   "source": [
    "feature_data = df[['age', 'drinks_i', 'smokes_i', 'sex_i']]\n",
    "\n",
    "x = feature_data.values\n",
    "print(x[0:2], '\\n')\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "print(x_scaled[0:2], '\\n')\n",
    "\n",
    "feature_data = pd.DataFrame(x_scaled, columns=feature_data.columns)\n",
    "print(feature_data.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we finally have our data ready for our training models.\n",
    "Now we will split the data:\n",
    "Allowed inputs are *lists, numpy arrays, scipy-sparse matrices* or *pandas dataframes.*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels = df[['drugs_i']].values # returns a numpy representation of the dataframe (removes labels)\n",
    "print(labels.shape)\n",
    "print(labels)\n",
    "\n",
    "labels = labels.ravel()\n",
    "print(labels.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(feature_data, df.drugs_i,\n",
    "                                                                    train_size=0.8,\n",
    "                                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors:\n",
    "\n",
    "I learned that the KNN doesnt perform well in this situation, because when we get a large enough **k value** it will \n",
    "just always guess the person doesn't do drugs because that is the majority.\n",
    "\n",
    "Or perhaps I just choose the worst features for this particular classification. \n",
    "\n",
    "Originally i was to classify them based on their `diet`, `age`, `income`, and `sex` ~75% accuracy\n",
    "\n",
    "Classifying based on `age`, `income`, `sex`, and `drinks` worked better ~77% \\n\n",
    "\n",
    "Getting rid of income worked a lot better ~81.2% accuracy \n",
    "    (this is because a lot of people don't display their income and so if we just got rid of it we have a lot \n",
    "    more training data to work with)\n",
    "\n",
    "Adding in `essay_len` doesn't improve the accuracy at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEJCAYAAACE39xMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAef0lEQVR4nO3de3RU9b338fc3M7lAbtxCAgEVEIQAIpBipUfxrqhH7cVztE9PPdoel7Weah+trW3tOa2u5+ipfdSeWpWjtkfrU1er9Cm6VOqlBZ8u9RjuBBCRawiXhEtCYkgymd/zx54kkxDIBCZM8svntdZes/dv75n5zk7y2b/57Zkdc84hIiL9X1qqCxARkeRQoIuIeEKBLiLiCQW6iIgnFOgiIp5QoIuIeCKc6gKkb1q2bNnIcDj8NDANHfgHiiiwNhKJfH327Nl7U12M9JwCXboUDoefLioqmlJQUHAgLS1NX1YYAKLRqFVVVZXs3r37aeDqVNcjPaeelxzNtIKCglqF+cCRlpbmCgoKagjelUk/pECXo0lTmA88sZ+5cqGf0g9O+qzq6urQgw8+WHA89/3JT34y8tChQ978fh/vvpg3b97p1dXVod6oSfoeb37hxT/79u0LPfPMMyOP575PPfVUYV1dnTe/30fbF5FI5Jj3W7JkyaYRI0a09Fph0qfopKj0WXfdddeYHTt2ZE6ePLlk3rx5tSNHjmz+wx/+MKypqcmuvPLKg4888khlbW1t2tVXXz1+165dGdFo1O65557KPXv2pO/duzd93rx5k4YOHRr54IMPNqb6tZyo+H0RDodddnZ2y8iRI5vXrVs3+JNPPim/+OKLJ+zatSujsbEx7dZbb91z9913VwMUFxdPLysrW19bW5s2f/78iXPmzKkrKyvLKSwsbFq8ePGmnJwcDat5RIEu3frOS6vGbtx9aHAyH3NSUe6nP/3SjB3H2uZnP/tZxVVXXTVow4YN6xYuXJj3+9//fujq1avXO+e4+OKLT3/99ddz9uzZEy4qKmr+y1/+sgmCnuzw4cNbnnjiicIlS5ZsHDVq1LG7sD11881jWbs2qfuCadM+5dlnE94Xr776au511113+ooVK8onT57cBPDCCy9sLSwsbKmrq7OZM2eWfOUrXzlQVFTUoWe+ffv2rN/85jeb586du+2KK64Y/9xzzw297bbb9if1tUhKefOWVPz2xhtv5C1dujSvpKSkZOrUqSWffPJJ1oYNG7JmzZrV8O677+Z94xvfKH7jjTdyhg8fPiCGF84888z61jAHeOihhwrPOOOMktmzZ0/ZvXt3enl5eVbn+xQXFzfOnTu3AWDmzJmfbt26NfNk1iy9Tz106VZ3PemTwTnHnXfeues73/lOded1y5cvX/fyyy/n/+AHPyh+6623ah9++OFdvVZINz3pk2Xw4MHR1vlXX301d8mSJbllZWUbcnNzo3PmzDmjoaHhiM5aRkZG2/BKKBRyXW0j/Zt+oNJn5efnt9TX16cBzJ8/v/b5558fUVNTkwawZcuW9J07d4a3bt2anpubG73tttv233nnnXtWrlw5GCA7O7uldVsfxO+Lzg4ePBjKz89vyc3Nja5YsSJr1apV2Se7Pukb1EOXPquoqKhl9uzZdRMnTpx64YUX1lx33XX7P/OZz0yGoIf6wgsvbNmwYUPmvffeOyYtLY1wOOx++ctfbgO48cYbq+fPnz9x5MiRzT6cFI3fF5mZmdGCgoLm1nVf/OIXaxYsWFAwadKkkgkTJhyeMWNGfSprldQx/Qs66cqqVau2zpgx44jhDfHfqlWrRsyYMeO0VNchPdftW1Ize9bM9prZ2qOsNzP7uZltMrPVZjYr+WWKiEh3Ehlj/DVw+THWzwcmxqZbgCdOvCwREempbgPdObcUONZnVa8BnnOB94EhZjYqWQWKiEhiknFStBiI/yhXRaztiI+OmdktBL14srOzZ0+ePDkJTy+94aGHHqK8vPxUM0t1KXISOeeorq6mtLRUJ9f6qGXLllU757q8rk8yAr2rv/gufxmccwuABQClpaWurKwsCU8vvWHLli3k5uYyfPhwFOoDg3OOffv2MXjwYPS32XeZ2bajrUtGoFcAY+OWxwCVSXhcSaExY8ZQUVFBVVVVqkuRkygrK4sxY8akugw5TskI9EXA7Wb2InA2UOOc671v6slJkZ6ezrhx41Jdhoj0QLeBbma/Bc4HRphZBfAvQDqAc+5J4DXgCmAT8ClwU28VKyIiR9dtoDvnbuhmvQO+mbSKRETkuHhzrQsRkYFOgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4omEAt3MLjezj8xsk5l9r4v1Q83sD2a22sz+28ymJb9UERE5lm4D3cxCwOPAfKAEuMHMSjpt9n1gpXPuTOCrwGPJLlRERI4tkR76HGCTc26zc64JeBG4ptM2JcDbAM65DcBpZlaY1EpFROSYEgn0YmBH3HJFrC3eKuALAGY2BzgVGJOMAkVEJDGJBLp10eY6LT8IDDWzlcA/AyuAyBEPZHaLmZWZWVlVVVWPixURkaMLJ7BNBTA2bnkMUBm/gXOuFrgJwMwM2BKb6LTdAmABQGlpaeeDgoiInIBEeugfAhPNbJyZZQDXA4viNzCzIbF1AF8HlsZCXkRETpJue+jOuYiZ3Q4sBkLAs865cjO7Nbb+SWAK8JyZtQDrgK/1Ys0iItKFRIZccM69BrzWqe3JuPn3gInJLU1ERHpC3xQVEfGEAl1ExBMKdBERTyjQRUQ8oUAXEfGEAl1ExBMKdBERTyjQRUQ8oUAXEfGEAl1ExBMKdBERTyjQRUQ8oUAXEfGEAl1ExBMKdBERTyjQRUQ8oUAXEfGEAl1ExBMKdBERTyjQRUQ8oUAXEfGEAl1ExBMKdBERTyjQRUQ8EU51AeIB52DXLsjPh+zsVFeTWs7BmjXw3nsQjUJ6+pFTONx1e6KTWapfZfecC15/6xSJQHMzNDUFU+t8V23drT+e+7TOR6NBffH7sHX+ZN5edx3cdNOJ7eMuKNAlcc5BRQWUl8O6de2369ZBbW0QNnPnwsUXwyWXQGkphEKprrr3VVXBm2/Cn/4UTLt29e7zhUKJHxTC4Y7B2nnqHLzJmJzr3dcfr/V1ZmQEU1fzrbeZme2/j6019uS2dTre+8ff1tef+GvvgrmTufPjlJaWurKyspQ8t3TDOdixo2Not94eOtS+XUEBTJ0KJSUwZUpwnzffhBUrgvVDhsAFFwThfsklMGFC/+hddqepKeiBL14cBPjy5cE+GzYseJ2XXRa87kGDgl5hsqbWXm5PppYWSEvrejI7+rrjmY71eKHQ0QO3q/BNZH047MfvUw+Z2TLnXGmX6xToA5hzsH1718FdV9e+3ciR7cEdu907djxrGjNYs7OGtTtrWb+rlpzMMLNOHco5eVE+u2UlBe8vxd56K3gOgFNPbQ/3iy6C4cNT87qPx6ZNQYAvXgx//nOwf0IhOOecIMAvuwxmzRoY70ikS5GWKPVNLdQ1RqhvjLTdBvMt1B1ubls/Z9wwLjhj5HE9jwJ9oItGuw7u9es7Bndh4RHB7aZMoTI9h7U7a9qnylqqDjUCQQdpQkEOJaPyqGloZvn2Axw6HAFgeHYGs04ZwoXhWs7ZvJyxZX8l9Jc/B8MzZjBzZnvAf+5zkJWVir3TtdpaeOed9l745s1B+7hx7QF+4YWQl4dzjr2HGmP7p5a1lTV8UlVHRiiN3KwwOZlhcrLSyckMBfOZ6eRkhcnNDJPTtr7jcnZGmLS0gdf7PJmcczRGoh0CuO5whPqmIIDrj9HeObTrGiMcbo4m9LzhNOPWeRO4+7IzjqtuBXpveOcdePXV4K1fVlYwZWa2z/d0OZyE0xmtwV1efmRwx4/ZFRUdEdyUlOCGDWPH/oag110ZhHd5ZS3765sACKUZE0fmMHV0PtOL85hWnM+UUXlkZ4bjSnBsqqpj2bYDLNt2gOXbDrC5Onju9JAxvTCbq5oq+ZutKzht5XtkfPB+MJSQlQXnnhuE+8UXw4wZwVv1k6WlJRg6ae2Fv/de0JaTEwT3pZfCZZfhJkyg4kBD7MAW7J+1O2uprms/wI0fkc2kwlxaoi4Ig7hQqGuM8GlTS0IlBeEfF/qdlnOzulpO77AuKz1EczRKcyRKc4ujuSVKYyRKc0v71Ni6Ltbe1BKlKW77jm1Be1MkaGuOb+uwTZSm2GM2tUSJRuNyxo6ctbihk/jDWNt5xLjWrkZZurp/V+c9myJR6htbOBTrLbdEE8u/QekhsjPDwUE5Kzjg5mSGyY5NOZmt69vb29eHyM1MJzu2TWY4rUO9PaVAT6aPP4a774ZFi4JAdi4YUz1RodDxHxQOHAjCu3NwjxrVZXAzbBjRqGPLvvq20F5TUUN5ZQ21sd51esiYVJjL9OJ8phbnM210HlNG5ZGV3vMhhX11jazYfpBl2w+wbOsBVlUcpDES9GYmDoYv1X3CudtXMX7le2R9tD64U0FBMCzTeoL1lFNOeBcfYefOoPe9eDG89Rbs2xe0z54Nl15K9JJL2TLpTNZWNcSCO9hXNQ3NQNDTmliYy7TRwcFtWnEek4s6HuC6Ev/WPAj5Zg4d7hj6Ryw3Rqg73NzWdih2kDjZf77hNCM9lEZ6yMgIp5ERSiM9nBZrSyMj1t66nB5KIyNshGIH5/i8cUfMgItb6HweMX59xzaOuA9dPQ6QEUrrGMBx74jaQzjUdqDMjq0L9aF3Swr0ZDh4EB54AH7+c8jMZNutd/L82Z8nKzebIVkhhoQdw9KiDElrIT8tSp5FySVCZqQJa2yExkY4fLh9il8+1rpElnNyug7uoUMBaIk6PqmqY+3OGtbsrKF8Zy3llTXUx3qKGeE0pozKawum6cX5TCzMITPcO+PBTZEo63bVtvXgy7btZ09t0MM9tfEgf1+zkXnbV3H66vfJrNoT3GnSpPZwv+CC4COSPdXQAO++294LLy8P2ouKiF56KbvPPo+ySaUs/zRMeWUN6yprO+6jotzYwS0I70mFucd1gEsW5xwNzS3tAX/EwaCZhuZoW/i2B2wQvB1DtzWcLRbMaXH3ad+2LwXbQKVAPxGRCDzzDPzwh7BvH5F/vIlHzvsHHt9QT2Y4jeaWKMd615YRTiN/UDpDBqUHt4PTyRuUzpBBGeQPSid/UJghg2Pzg9Pbts0blE56qOdDDs0tUT7eU9c2ZLJ2Zw3rdtW2je8NSg9RMjovrleZz+kjc47ruZLFOUdlzWHKtu5n+bYDLNt+gPW7DtHSEmVi9Xa+sG8dF+xYzenrlxFu+BSXlobNmdM+/n722cHQ15EPHIR2ay986VI4fBiXkUHd2XPZNOMc3h0/m7fTC9mw+1Dbu4ZB6SGmxvZP622q95FIKwX68Xr7bfj2t4Mvipx3Huvv+THfXA+bq+v5x7mn8d3LJ5MZTuNQY4TahmYOftpMTUMwHWxoCuZjbfHrWqe6xsgxnz47I8SQwRmxA0D7ASE/Fvit84cOR2I97xrW7z5EUyyYcjLDsfDOZ/qY4HZ8QU6/6GXVN0ZYVXEwCPjY1FDfwMzKj7ikYjUX7lzNuC3rSItGcTk52Lx5Qbife24wLNZ6MnPnTgAOnnY6a6aezZvFM1iYN4G6UCYAuVnhth53EOD5jBuR3S/2kQxMCvSeih8nHzeO5gcf4tG8aTyxZDOj8gfx0y+dydzTR5zw0zS3RIMDQXzQdzoAHGxoorahc1tzW2i3yssKtw2XtI55nzY825tPSkSjjs3VwcnWsq1BL756xx7O2b6ac7et4oIdqyiuqmjbvj47j7LTZ/H66OksPW0mlXkjGZadEbwraX13MjqfscMGndAJKpGT7YQD3cwuBx4DQsDTzrkHO63PB34DnELw7dOHnXO/OtZj9slAP3gQ7r8f/uM/gpONP/whG/7uJr696CPW76rlutljuO9vS8jLSk91pRxubmkL+MEZIcYMHXjBtL++iRXb23vwVWs/YvrWtWwfMoo9Z0ynZOxQpo7ObzthWZSXNeD2kfjnhALdzELARuASoAL4ELjBObcubpvvA/nOue+aWQHwEVDknDvqxz/6VKBHIvD003DffcEnHW6+mZaf3M9TG+t55M2N5A9K59++cCaXlBSmulI5huaWKJv21jEiJ5OC3MxUlyPSK44V6Il8+HkOsMk5tzn2YC8C1wDr4rZxQK4F3Z8cYD9w7AHivuLtt+HOO2HtWjjvPHj0UbaMncRdv1vJ8u0HuWJ6EQ9cO51h2V2cdJM+JT0UfFpHZKBK5LR9MbAjbrki1hbvF8AUoBJYA9zhnDvia1NmdouZlZlZWVVV1XGWnCQffwzXXBN8FK6+Hl56ieg7f+a5w0O54rF32bS3jseuP4vHvzxLYS4i/UIiPfSuBh07j9NcBqwELgQmAG+a2bvOudoOd3JuAbAAgiGXnpebBPHj5FlZ8OCDcMcdVB523POrD/l/m6o5b1IB//7FMynK70NfRRcR6UYigV4BjI1bHkPQE493E/CgCwbkN5nZFmAy8N9JqTIZIhH4z/+EH/0oGCf/2tfg/vtxhYUsXL6Tf32lnJao44Frp/E/zj5FJ89EpN9JJNA/BCaa2ThgJ3A98OVO22wHLgLeNbNC4AxgczILPSFvvRV8nnztWpg3Dx59FM46i+q6Rr7//DL+tG4PpacO5Wd/N4NThw/wf9AgIv1Wt4HunIuY2e3AYoKPLT7rnCs3s1tj658E7gd+bWZrCIZovuucq+7FuhPz8cdw113wyivBVfJefhk+/3kw4421u/nBH9Zw6HCEe+dP5uvnjteXSUSkX0voEn/OudeA1zq1PRk3XwlcmtzSTkDncfKHHoJvfQuysqhpaObHr5SzcPlOpo7O4//801mcUZSb6opFRE6YX/+CrnWc/L77YP/+YJz8gQeC63wD735cxT0vrWbvoUa+deHp3H7hRDLCuj6HiPjBn0B/881gnLy8vMM4OcCnTREefH0Dz723jfEF2bz8jbmcNXZIigsWEUmu/h/oGzcG11155RUYPx4WLoRrr227ov2ybQe463cr2brvU27+3DjuufyMlF7yVESkt/TfQD9woH2cfNCgYJz8jjuCa7AAjZEWHn3rY55a8gmj8gfx23/6LOdM6Ef/w1JEpIf6X6BHIrBgQfB58v374etfD4K9sP06K+sqa/mfv1vJht2H+PvSsfzwqink9oELaomI9Kb+F+i//jV885tw/vnwyCNt4+QQ/Guvp5Zu5tG3NpI/KINnbizloim6oJaIDAz9L9C/+tXgnxxfeWWH/wK7uaqOu36/ihXbD3Ll9FHcf+00XYNFRAaU/hfoGRlw1VVti9Go4/n3t/Fvr68nMxzisevP4uoZo/XVfREZcPpfoMfZebCBe15axV837WPepAL+/UtnUpinC2qJyMDULwPdOcfLy3fy40XltDjH//r8dG6YM1a9chEZ0PpdoFfXNXLvwjW8uW4Pc04bxsPXzeCU4YNTXZaISMr1u0B/f/M+lmys4gdXTOHmvxmnC2qJiMT0u0C/6szRzDplKKOHDEp1KSIifUq/vDKVwlxE5Ej9MtBFRORICnQREU8o0EVEPKFAFxHxhAJdRMQTCnQREU8o0EVEPKFAFxHxhAJdRMQTCnQREU8o0EVEPKFAFxHxhAJdRMQTCnQREU8o0EVEPKFAFxHxhAJdRMQTCnQREU8o0EVEPKFAFxHxREKBbmaXm9lHZrbJzL7XxfrvmNnK2LTWzFrMbFjyyxURkaPpNtDNLAQ8DswHSoAbzKwkfhvn3E+dc2c5584C7gWWOOf290bBIiLStUR66HOATc65zc65JuBF4JpjbH8D8NtkFCciIolLJNCLgR1xyxWxtiOY2WDgcuDlEy9NRER6IpFAty7a3FG2/Vvgr0cbbjGzW8yszMzKqqqqEq1RREQSkEigVwBj45bHAJVH2fZ6jjHc4pxb4Jwrdc6VFhQUJF6liIh0K5FA/xCYaGbjzCyDILQXdd7IzPKBecAfk1uiiIgkItzdBs65iJndDiwGQsCzzrlyM7s1tv7J2KafB/7knKvvtWpFROSozLmjDYf3rtLSUldWVpaS5xYR6a/MbJlzrrSrdfqmqIiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHgioUA3s8vN7CMz22Rm3zvKNueb2UozKzezJcktU0REuhPubgMzCwGPA5cAFcCHZrbIObcubpshwC+By51z281sZG8VLCIiXUukhz4H2OSc2+ycawJeBK7ptM2XgYXOue0Azrm9yS1TRES6k0igFwM74pYrYm3xJgFDzewvZrbMzL7a1QOZ2S1mVmZmZVVVVcdXsYiIdCmRQLcu2lyn5TAwG7gSuAy4z8wmHXEn5xY450qdc6UFBQU9LlZERI6u2zF0gh752LjlMUBlF9tUO+fqgXozWwrMADYmpUoREelWIj30D4GJZjbOzDKA64FFnbb5I3CumYXNbDBwNrA+uaWKiMixdNtDd85FzOx2YDEQAp51zpWb2a2x9U8659ab2RvAaiAKPO2cW9ubhYuISEfmXOfh8JOjtLTUlZWVpeS5RUT6KzNb5pwr7WqdvikqIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcSCnQzu9zMPjKzTWb2vS7Wn29mNWa2Mjb9KPmliojIsYS728DMQsDjwCVABfChmS1yzq3rtOm7zrmreqFGERFJQCI99DnAJufcZudcE/AicE3vliUiIj2VSKAXAzvilitibZ2dY2arzOx1M5ualOpERCRh3Q65ANZFm+u0vBw41TlXZ2ZXAP8XmHjEA5ndAtwSW6wzs496UmwfNAKoTnURfYj2R0faH+20Lzo6kf1x6tFWJBLoFcDYuOUxQGX8Bs652rj518zsl2Y2wjlX3Wm7BcCChEruB8yszDlXmuo6+grtj460P9ppX3TUW/sjkSGXD4GJZjbOzDKA64FFnYorMjOLzc+JPe6+ZBcrIiJH120P3TkXMbPbgcVACHjWOVduZrfG1j8JfAn4hplFgAbgeudc52EZERHpRYkMueCcew14rVPbk3HzvwB+kdzS+gVvho+SRPujI+2PdtoXHfXK/jB1pEVE/KCv/ouIeEKBfhzMbKyZ/dnM1ptZuZndkeqaUs3MQma2wsxeTXUtqWZmQ8zsJTPbEPsdOSfVNaWSmX079ney1sx+a2ZZqa7pZDKzZ81sr5mtjWsbZmZvmtnHsduhyXguBfrxiQB3OeemAJ8FvmlmJSmuKdXuANanuog+4jHgDefcZGAGA3i/mFkx8C2g1Dk3jeCDFdentqqT7tfA5Z3avge87ZybCLwdWz5hCvTj4Jzb5ZxbHps/RPAH29W3ZwcEMxsDXAk8nepaUs3M8oDzgGcAnHNNzrmDqa0q5cLAIDMLA4Pp9D0W3znnlgL7OzVfA/xXbP6/gGuT8VwK9BNkZqcBM4EPUltJSj0K3ANEU11IHzAeqAJ+FRuCetrMslNdVKo453YCDwPbgV1AjXPuT6mtqk8odM7tgqCDCIxMxoMq0E+AmeUALwN3xn9bdiAxs6uAvc65ZamupY8IA7OAJ5xzM4F6kvR2uj+KjQ1fA4wDRgPZZvaV1FblLwX6cTKzdIIwf8E5tzDV9aTQ54CrzWwrwZU4LzSz36S2pJSqACqcc63v2F4iCPiB6mJgi3OuyjnXDCwE5qa4pr5gj5mNAojd7k3GgyrQj0PsMgfPAOudc/871fWkknPuXufcGOfcaQQnu95xzg3YHphzbjeww8zOiDVdBHT+3wEDyXbgs2Y2OPZ3cxED+CRxnEXAjbH5G4E/JuNBE/qmqBzhc8A/AGvMbGWs7fuxb9SK/DPwQuzaR5uBm1JcT8o45z4ws5cIrsgaAVYwwL41ama/Bc4HRphZBfAvwIPA78zsawQHveuS8lz6pqiIiB805CIi4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHji/wO6AQz2JKzq3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_test = []\n",
    "score_train = []\n",
    "k_values = list(range(1, 11, 1))\n",
    "for k in k_values:\n",
    "    print(k, end=' ')\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(train_data, train_labels)\n",
    "    score_train.append(model.score(train_data, train_labels))\n",
    "    score_test.append(model.score(test_data, test_labels))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "# plt.rcParams['figure.figsize'] = (9, 9)\n",
    "ax.plot(k_values, score_test, label=\"test\")\n",
    "ax.plot(k_values, score_train, label='train', c='r')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.10), ncol=2)\n",
    "plt.ylim(0.5, 1)\n",
    "# plt.axvline(10, 0, 1, c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 0.8299211671961407\n",
      "TEST: 0.8217437345570067\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=6)\n",
    "model.fit(train_data, train_labels)\n",
    "print('TRAIN:', model.score(train_data, train_labels))\n",
    "print('TEST:', model.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEST RESULTS:\n",
    "    \n",
    "Accuracy of 82.2% under the following settings:\n",
    "    k = 6\n",
    "    training set: 'age', 'sex_i', 'drinks', 'smokes'\n",
    "    Label: 'drugs_i'\n",
    "\n",
    "Accuracy of ~99% when only considering people who do drugs often and everything else as 0.This is because very few \n",
    "people fall in this category so the classifier can just always assume that they aren't doing drugs and will end up with reasonable accuracy.\n",
    "\n",
    "We get an accuracy ~82.6% when only focusing on people who do drugs sometimes (this is because they are the majority out of the drug users so its very similar to our first result.\n",
    "\n",
    "When trying to predict sex with the same features we get a shitty accuracy of ~58.05%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "With the default SVM the shape of the decision boundary is one vs the rest (ovr) so it can only classifiy something as \n",
    "is or isn't to change that we need to set the shape to one vs one (ovo).\n",
    "Surprisingly this didn't increase the accuracy significantly :(\n",
    "       https://scikit-learn.org/stable/modules/svm.html#multi-class-classification\n",
    "\n",
    "Drinking and smoking are highly correlated with whether or not someone does drugs or not.\n",
    "On default settings a *radial bias kernel* performed better that *poly, or linear*.\n",
    "\n",
    "Default value for gamma (float) is 1/n_features (determines how sensitive the model is to data).\n",
    "The C value (float) determines how much room for outliers we will allow (hard vs soft margins).\n",
    "\n",
    "    A C value of 0.82 performed the best with an accuracy of ~83.6%\n",
    "    Combined with a gamma of 2.45 ~83.61%\n",
    "\n",
    "    training set: 'age', 'sex_i', 'drinks', 'smokes'\n",
    "    Label: drugs_i\n",
    "\n",
    "When doing the same thing but with sex as the label I got an accuracy of ~58.05%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(33996, 4)\n",
      "            age  drinks_i  smokes_i  sex_i\n",
      "34349  0.705882       0.2  0.000000    0.0\n",
      "14945  0.117647       0.4  1.000000    0.0\n",
      "7880   0.274510       0.4  0.333333    0.0\n",
      "9959   0.176471       0.4  0.000000    0.0\n",
      "(33996,)\n",
      "48467    0\n",
      "21210    2\n",
      "11169    2\n",
      "14144    0\n",
      "Name: drugs_i, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "c = 0.82\n",
    "g = 2.45\n",
    "print(max(train_labels))\n",
    "print(train_data.shape)\n",
    "print(train_data.head(n=4))\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(train_labels.head(n=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8310389457583245\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf', C=c, gamma=g, \n",
    "            decision_function_shape= 'ovo')\n",
    "model.fit(train_data, train_labels)\n",
    "score = model.score(test_data, test_labels)\n",
    "print(score)\n",
    "\n",
    "print(max(model.predict(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model never once made a classification to say that an individual did drugs **often** this is why our results still seem to follow a OVR type SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Often:\n",
      "              age    drinks_i    smokes_i       sex_i\n",
      "count  432.000000  432.000000  432.000000  432.000000\n",
      "mean     0.169208    0.581944    0.720679    0.337963\n",
      "std      0.094224    0.145299    0.315721    0.473564\n",
      "min      0.000000    0.400000    0.333333    0.000000\n",
      "25%      0.098039    0.400000    0.333333    0.000000\n",
      "50%      0.156863    0.600000    1.000000    0.000000\n",
      "75%      0.215686    0.600000    1.000000    1.000000\n",
      "max      0.490196    1.000000    1.000000    1.000000\n",
      "\n",
      "Sometimes:\n",
      "       age  drinks_i  smokes_i  sex_i\n",
      "count  0.0       0.0       0.0    0.0\n",
      "mean   NaN       NaN       NaN    NaN\n",
      "std    NaN       NaN       NaN    NaN\n",
      "min    NaN       NaN       NaN    NaN\n",
      "25%    NaN       NaN       NaN    NaN\n",
      "50%    NaN       NaN       NaN    NaN\n",
      "75%    NaN       NaN       NaN    NaN\n",
      "max    NaN       NaN       NaN    NaN\n",
      "\n",
      "Never:\n",
      "               age     drinks_i     smokes_i        sex_i\n",
      "count  8067.000000  8067.000000  8067.000000  8067.000000\n",
      "mean      0.292735     0.360208     0.064336     0.427420\n",
      "std       0.193434     0.139775     0.180475     0.494735\n",
      "min       0.000000     0.000000     0.000000     0.000000\n",
      "25%       0.156863     0.400000     0.000000     0.000000\n",
      "50%       0.235294     0.400000     0.000000     0.000000\n",
      "75%       0.392157     0.400000     0.000000     1.000000\n",
      "max       1.000000     1.000000     1.000000     1.000000\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_data)\n",
    "print(max(prediction))\n",
    "\n",
    "often = [i for i in range(len(prediction)) if prediction[i] == 2]\n",
    "sometimes = [i for i in range(len(prediction)) if prediction[i] == 1]\n",
    "never = [i for i in range(len(prediction)) if prediction[i] == 0]\n",
    "\n",
    "# pd.set_option('max_rows', 100)\n",
    "\n",
    "print(\"Often:\")\n",
    "print(test_data.iloc[often].describe())\n",
    "print(\"\\nSometimes:\")\n",
    "print(test_data.iloc[sometimes].describe())\n",
    "print(\"\\nNever:\")\n",
    "print(test_data.iloc[never].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To create a plot of the data accross various gamma or margin(c) values we can do the following:**\n",
    "\n",
    "    print(prediction)\n",
    "    print('druggy' if prediction == 1 else 'clean')\n",
    "    # gamma = list(np.linspace(2.25, 3, 5))\n",
    "    margins = list(np.linspace(0.82, 3, 10))\n",
    "    scores = []\n",
    "    for c in margins:\n",
    "        model = SVC(kernel='rbf', C=c, gamma=g)\n",
    "        model.fit(train_data, train_labels)\n",
    "        score = model.score(test_data, test_labels)\n",
    "        print(score)\n",
    "        scores.append(score)\n",
    "\n",
    "    plt.plot(margins, scores)\n",
    "    plt.ylim(0.6, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes:\n",
    "This classifier works best with textual data so we need to completely start over fresh and get new data for \n",
    "it to work with.\n",
    "\n",
    "With this classifier I intend to use the essays to determine whether or not a person does drugs or not\n",
    "1. Create a new column to contain all the essays concatenated.\n",
    "2. Augment the data with natural language processing (lowercase everything and remove punctuation).\n",
    "3. Run it through a counter vectorizer to format the data and get counts for how the essays are structured for each individual in the dataset.\n",
    "\n",
    "Then I can use these counts to train the model!\n",
    "\n",
    "**Accuracies:** (Bigram worked the best, however monogram was the fastest and as we went up to trigram it got exponentially \n",
    "longer).\n",
    "* bigram and trigam: ~82.21%\n",
    "* only bigram: ~82.33%\n",
    "* monogram and bigram: ~82.42%\n",
    "* monogram: ~80.98%\n",
    "\n",
    "**Alternate drug_i mapping accuracies:**\n",
    "* sometimes=1 and often=2: ~82.26%\n",
    "* sometimes=1 and often=1: ~82.33%\n",
    "\n",
    "**Best settings:**\n",
    "* drugs{never=0, sometimes=1, often=2}\n",
    "\n",
    "\n",
    "When using this same technique but with sex it was poor with only 77.07% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0    34830\n",
      "1     7665\n",
      "Name: drugs_i, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# creating label data:\n",
    "df.dropna(subset=['drugs'], inplace=True)\n",
    "df['drugs_i'] = df.drugs.map({'never': 0, 'sometimes': 1, 'often': 1})\n",
    "\n",
    "print(df.drugs.isna().any())\n",
    "print(df.drugs_i.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature data:\n",
    "list_essays = ['essay' + str(i) for i in range(10)]\n",
    "\n",
    "# Removing nan and joining all essays into one column\n",
    "all_essays = df[list_essays].replace(np.nan, '', regex=True)\n",
    "df['essays'] = all_essays[list_essays].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(df['essays'], df['drugs_i'],\n",
    "                                                                    train_size=0.8, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count Vectorizer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = CountVectorizer(lowercase=True, ngram_range=(1, 2))     # token_pattern by default ignores punctuation\n",
    "count.fit(df['essays'])\n",
    "print(type(list(test_data)))\n",
    "print(list(test_data))\n",
    "\n",
    "test_data_count = count.transform(list(test_data))\n",
    "train_data_count = count.transform(list(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the model & testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8236263089775268\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(train_data_count, train_labels)\n",
    "print(model.score(test_data_count, test_labels))\n",
    "print(model.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
